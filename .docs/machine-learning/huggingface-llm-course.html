<!DOCTYPE html> <html lang="en"><head>
<title>HuggingFace: LLM Course</title>
<base href="..">
<meta name="pathname" content="machine-learning/huggingface-llm-course.html">
<meta name="description" content="GT Notes - HuggingFace: LLM Course">
<meta property="og:title" content="HuggingFace: LLM Course">
<meta property="og:description" content="GT Notes - HuggingFace: LLM Course">
<meta property="og:type" content="website">
<meta property="og:url" content="machine-learning/huggingface-llm-course.html">
<meta property="og:image" content="undefined">
<meta charset="UTF-8"><meta property="og:site_name" content="GT Notes"><meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes, minimum-scale=1.0, maximum-scale=5.0"><script async="" id="webpage-script" src="site-lib/scripts/webpage.js" onload="this.onload=null;this.setAttribute(&quot;loaded&quot;, &quot;true&quot;)"></script><link rel="icon" href="site-lib/media/favicon.png"><link rel="stylesheet" href="site-lib/styles/obsidian.css"><link rel="preload" href="site-lib/styles/other-plugins.css" as="style" onload="this.onload=null;this.rel='stylesheet'"><noscript><link rel="stylesheet" href="site-lib/styles/other-plugins.css"></noscript><link rel="stylesheet" href="site-lib/styles/theme.css"><link rel="preload" href="site-lib/styles/global-variable-styles.css" as="style" onload="this.onload=null;this.rel='stylesheet'"><noscript><link rel="stylesheet" href="site-lib/styles/global-variable-styles.css"></noscript><link rel="preload" href="site-lib/styles/supported-plugins.css" as="style" onload="this.onload=null;this.rel='stylesheet'"><noscript><link rel="stylesheet" href="site-lib/styles/supported-plugins.css"></noscript><link rel="preload" href="site-lib/styles/main-styles.css" as="style" onload="this.onload=null;this.rel='stylesheet'"><noscript><link rel="stylesheet" href="site-lib/styles/main-styles.css"></noscript><style>body{--line-width:40em;--line-width-adaptive:40em;--file-line-width:40em;--sidebar-width:min(20em, 80vw);--collapse-arrow-size:11px;--tree-vertical-spacing:1.3em;--sidebar-margin:12px}:root{background-color:#202124}.sidebar{height:100%;font-size:14px;z-index:10;min-width:calc(var(--sidebar-width) + var(--divider-width-hover));max-width:calc(var(--sidebar-width) + var(--divider-width-hover));position:relative;overflow:hidden;overflow:clip;transition:min-width ease-in-out,max-width ease-in-out;transition-duration:.2s;contain:size}#left-sidebar{left:0}#right-sidebar{right:0}.sidebar.is-collapsed{min-width:0;max-width:0}.sidebar.floating{position:absolute}.sidebar .leaf-content{height:100%;min-width:calc(var(--sidebar-width) - var(--divider-width-hover));top:0;padding:var(--sidebar-margin);padding-top:4em;line-height:var(--line-height-tight);background-color:var(--background-secondary);transition:background-color,border-right,border-left,box-shadow;transition-duration:var(--color-fade-speed);transition-timing-function:ease-in-out;position:absolute;display:flex;flex-direction:column}.sidebar:not(.is-collapsed) .leaf-content{min-width:calc(max(100%,var(--sidebar-width)) - 3px);max-width:calc(max(100%,var(--sidebar-width)) - 3px)}#left-sidebar-content{left:0;border-top-right-radius:var(--radius-l);border-bottom-right-radius:var(--radius-l)}#right-sidebar-content{right:0;border-top-left-radius:var(--radius-l);border-bottom-left-radius:var(--radius-l)}.sidebar #left-sidebar-content,.sidebar #right-sidebar-content{contain:none!important;container-type:normal!important;animation:none!important}.sidebar:has(.leaf-content:empty):has(.topbar-content:empty){display:none}.sidebar-topbar{height:calc(2.3em + 2 * var(--sidebar-margin));width:var(--sidebar-width);padding:var(--sidebar-margin);z-index:1;position:fixed;display:flex;align-items:center;transition:width ease-in-out;transition-duration:inherit}.sidebar.is-collapsed .sidebar-topbar{width:calc(2.3em + var(--sidebar-margin) * 2)}.sidebar .sidebar-topbar.is-collapsed{width:0}#left-sidebar .sidebar-topbar{left:0;flex-direction:row;border-top-right-radius:var(--radius-l)}#right-sidebar .sidebar-topbar{right:0;flex-direction:row-reverse;border-top-left-radius:var(--radius-l)}#left-sidebar .topbar-content{margin-right:calc(2.3em + var(--sidebar-margin));flex-direction:row}#right-sidebar .topbar-content{margin-left:calc(2.3em + var(--sidebar-margin));flex-direction:row-reverse}.topbar-content{overflow:hidden visible;overflow:clip visible;width:100%;height:100%;display:flex;align-items:center;transition:inherit}.sidebar.is-collapsed .topbar-content{width:0;transition:inherit}.clickable-icon.sidebar-collapse-icon{background-color:transparent;color:var(--icon-color-focused);padding:2px!important;margin:0!important;height:100%!important;width:2.3em!important;margin-inline:0.14em!important;position:absolute}#left-sidebar .clickable-icon.sidebar-collapse-icon{transform:rotateY(180deg);right:var(--sidebar-margin)}#right-sidebar .clickable-icon.sidebar-collapse-icon{transform:rotateY(180deg);left:var(--sidebar-margin)}.clickable-icon.sidebar-collapse-icon svg.svg-icon{width:100%;height:100%}.feature-title{margin-left:1px;text-transform:uppercase;letter-spacing:.06em;margin-top:.75em;margin-bottom:.75em}.feature-header{display:flex;align-items:center;padding-top:0;font-size:1em;padding-left:0}body.floating-sidebars .sidebar{position:absolute}body{transition:background-color var(--color-fade-speed) ease-in-out}#navbar:not(:empty){display:flex;align-items:center;justify-content:space-between;padding:.5em 1em;width:100%}#main{display:flex;flex-direction:column;height:100%;width:100%;align-items:stretch;justify-content:center}#main-horizontal{display:flex;flex-direction:row;flex-grow:1;width:100%;align-items:stretch;justify-content:center}#center-content{flex-basis:100%;max-width:100%;width:100%;height:100%;display:flex;flex-direction:column;align-items:center;transition:opacity .2s ease-in-out;contain:inline-size}.hide{opacity:0!important;transition:opacity .2s ease-in-out;pointer-events:none}#center-content>.obsidian-document{padding-left:2em;padding-right:1em;margin-bottom:0;width:100%;width:-webkit-fill-available;width:-moz-available;width:fill-available;transition:background-color var(--color-fade-speed) ease-in-out;border-top-right-radius:var(--window-radius,var(--radius-m));border-top-left-radius:var(--window-radius,var(--radius-m));overflow-x:hidden!important;overflow-y:auto!important;display:flex!important;flex-direction:column!important;align-items:center!important;contain:inline-size}body #center-content>.obsidian-document>.markdown-preview-sizer{padding-bottom:80vh;width:100%;max-width:var(--line-width);flex-basis:var(--line-width);transition:background-color var(--color-fade-speed) ease-in-out;contain:inline-size}#center-content>.obsidian-document>div{width:100%!important;transition:background-color var(--color-fade-speed) ease-in-out;contain:inline-size}#center-content>.obsidian-document:not([data-type=markdown]).embed{display:flex;padding:1em;height:100%;width:100%;align-items:center;justify-content:center}#center-content>.obsidian-document:not([data-type=markdown]).embed>*{max-width:100%;max-height:100%;object-fit:contain}:not(h1,h2,h3,h4,h5,h6,li):has(> :is(.math,table)){overflow-x:auto!important}#center-content>.obsidian-document:not([data-type=markdown]){overflow-x:auto;contain:content;padding:0;margin:0;height:100%}.obsidian-document[data-type=attachment]{display:flex;flex-direction:column;align-items:center;justify-content:center;height:100%;width:100%}.obsidian-document[data-type=attachment]>*{outline:0;border:none;box-shadow:none}.obsidian-document[data-type=attachment] :is(img){max-width:90%;max-height:90%;object-fit:contain}.obsidian-document[data-type=attachment]>:is(audio){width:100%;max-width:min(90%,var(--line-width))}.obsidian-document[data-type=attachment]>:is(embed,iframe,video){width:100%;height:100%;max-width:100%;max-height:100%;object-fit:contain}.canvas-wrapper>:is(.header,.footer){z-index:100;position:absolute;display:flex;justify-content:center;flex-direction:column;width:100%;align-items:center}.scroll-highlight{position:absolute;width:100%;height:100%;pointer-events:none;z-index:1000;background-color:hsla(var(--color-accent-hsl),.25);opacity:0;padding:1em;inset:50%;translate:-50% -50%;border-radius:var(--radius-s)}</style><script defer="">async function loadIncludes(){let e=document.querySelectorAll("link[itemprop='include']");for(const t of e){let e=t.getAttribute("href");try{let o="";if(e.startsWith("https:")||e.startsWith("http:")||"file:"!=window.location.protocol){const n=await fetch(e);if(!n.ok){console.log("Could not include file: "+e),t?.remove();continue}o=await n.text()}else{const t=document.getElementById(btoa(encodeURI(e)));if(t){const e=JSON.parse(decodeURI(atob(t.getAttribute("value")??"")));o=e?.data??""}}let n=document.createRange().createContextualFragment(o);t.before(n),t.remove(),console.log("Included text: "+o),console.log("Included file: "+e)}catch(o){t?.remove(),console.log("Could not include file: "+e,o);continue}}}document.addEventListener("DOMContentLoaded",(()=>{loadIncludes()}));let isFileProtocol="file:"==location.protocol;function waitLoadScripts(e,t){let o=e.map((e=>document.getElementById(e+"-script")));!function e(n){let l=o[n],c=n+1;l?(l&&"true"!=l.getAttribute("loaded")||n<o.length&&e(c),n<o.length&&l.addEventListener("load",(()=>e(c)))):n<o.length?e(c):t()}(0)}</script></head><body class="publish css-settings-manager show-inline-title show-ribbon is-focused"><script defer="">let theme=localStorage.getItem("theme")||(window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light");"dark"==theme?(document.body.classList.add("theme-dark"),document.body.classList.remove("theme-light")):(document.body.classList.add("theme-light"),document.body.classList.remove("theme-dark")),window.innerWidth<480?document.body.classList.add("is-phone"):window.innerWidth<768?document.body.classList.add("is-tablet"):window.innerWidth<1024?document.body.classList.add("is-small-screen"):document.body.classList.add("is-large-screen")</script><div class="parsed-feature-container" style="display: contents;"><link itemprop="include" href="site-lib/html/custom-head-content-content.html"></div><div id="main"><div id="navbar"></div><div id="main-horizontal"><div id="left-content" class="leaf" style="--sidebar-width: var(--sidebar-width-left);"><div id="left-sidebar" class="sidebar"><div class="sidebar-handle"></div><div class="sidebar-topbar"><div class="topbar-content"><div id="search-container"><div id="search-wrapper"><input enterkeyhint="search" type="search" spellcheck="false" placeholder="Search..."><div aria-label="Clear search" id="search-clear-button"></div></div></div></div><div class="clickable-icon sidebar-collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="100%" height="100%" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="3" stroke-linecap="round" stroke-linejoin="round" class="svg-icon"><path d="M21 3H3C1.89543 3 1 3.89543 1 5V19C1 20.1046 1.89543 21 3 21H21C22.1046 21 23 20.1046 23 19V5C23 3.89543 22.1046 3 21 3Z"></path><path d="M10 4V20"></path><path d="M4 7H7"></path><path d="M4 10H7"></path><path d="M4 13H7"></path></svg></div></div><div class="sidebar-content-wrapper"><div id="left-sidebar-content" class="leaf-content"><link itemprop="include" href="site-lib/html/file-tree-content.html"></div></div><script defer="">let ls = document.querySelector("#left-sidebar"); ls.classList.toggle("is-collapsed", window.innerWidth < 768); ls.style.setProperty("--sidebar-width", localStorage.getItem("sidebar-left-width"));</script></div></div><div id="center-content" class="leaf"><div class="obsidian-document markdown-preview-view markdown-rendered node-insert-event is-readable-line-width allow-fold-headings allow-fold-lists show-indentation-guide show-properties" data-type="markdown"><style id="MJX-CHTML-styles">mjx-c.mjx-c2217::before{padding:.465em .5em 0 0;content:"∗"}mjx-c.mjx-c1D460.TEX-I::before{padding:.442em .469em .01em 0;content:"s"}mjx-c.mjx-c66::before{padding:.705em .372em 0 0;content:"f"}mjx-c.mjx-c64::before{padding:.694em .556em .011em 0;content:"d"}mjx-c.mjx-c1D459.TEX-I::before{padding:.694em .298em .011em 0;content:"l"}mjx-c.mjx-c75::before{padding:.442em .556em .011em 0;content:"u"}mjx-c.mjx-c1D45C.TEX-I::before{padding:.441em .485em .011em 0;content:"o"}mjx-c.mjx-c1D45D.TEX-I::before{padding:.442em .503em .194em 0;content:"p"}mjx-c.mjx-c1D436.TEX-I::before{padding:.705em .76em .022em 0;content:"C"}mjx-c.mjx-c1D41B.TEX-B::before{padding:.694em .639em .006em 0;content:"b"}mjx-c.mjx-c2C.TEX-B::before{padding:.171em .319em .194em 0;content:","}mjx-c.mjx-c1D453.TEX-I::before{padding:.705em .55em .205em 0;content:"f"}mjx-c.mjx-c1D416.TEX-B::before{padding:.686em 1.189em .007em 0;content:"W"}mjx-c.mjx-c1D432.TEX-B::before{padding:.444em .607em .2em 0;content:"y"}mjx-c.mjx-c79::before{padding:.431em .528em .204em 0;content:"y"}mjx-c.mjx-c24.TEX-B::before{padding:.75em .575em .056em 0;content:"$"}mjx-c.mjx-c1D703.TEX-I::before{padding:.705em .469em .01em 0;content:"θ"}mjx-c.mjx-c1D702.TEX-I::before{padding:.442em .497em .216em 0;content:"η"}mjx-c.mjx-c1D45F.TEX-I::before{padding:.442em .451em .011em 0;content:"r"}mjx-c.mjx-c1D454.TEX-I::before{padding:.442em .477em .205em 0;content:"g"}mjx-munder{display:inline-block;text-align:left}mjx-over{text-align:left}mjx-munder:not([limits=false]){display:inline-table}mjx-munder>mjx-row{text-align:left}mjx-under{padding-bottom:.1em}mjx-c.mjx-c78::before{padding:.431em .528em 0 0;content:"x"}mjx-c.mjx-c67::before{padding:.453em .5em .206em 0;content:"g"}mjx-c.mjx-c2061::before{padding:0;content:""}mjx-c.mjx-c72::before{padding:.442em .392em 0 0;content:"r"}mjx-stretchy-v.mjx-c2016 mjx-ext mjx-c::before{content:"∥";width:.556em}mjx-c.mjx-c42::before{padding:.683em .708em 0 0;content:"B"}mjx-c.mjx-c7C::before{padding:.75em .278em .249em 0;content:"|"}mjx-c.mjx-c2F::before{padding:.75em .5em .25em 0;content:"/"}mjx-c.mjx-c1D434.TEX-I::before{padding:.716em .75em 0 0;content:"A"}mjx-c.mjx-c1D44F.TEX-I::before{padding:.694em .429em .011em 0;content:"b"}mjx-c.mjx-c1D44B.TEX-I::before{padding:.683em .852em 0 0;content:"X"}mjx-c.mjx-c1D465.TEX-I::before{padding:.442em .572em .011em 0;content:"x"}mjx-c.mjx-c1D441.TEX-I::before{padding:.683em .888em 0 0;content:"N"}mjx-c.mjx-c1D447.TEX-I::before{padding:.677em .704em 0 0;content:"T"}mjx-c.mjx-c73::before{padding:.448em .394em .011em 0;content:"s"}mjx-c.mjx-c57::before{padding:.683em 1.028em .022em 0;content:"W"}mjx-c.mjx-c20D7.TEX-V::before{padding:.714em .5em 0 0;content:"→"}mjx-c.mjx-c1D464.TEX-I::before{padding:.443em .716em .011em 0;content:"w"}mjx-c.mjx-c65::before{padding:.448em .444em .011em 0;content:"e"}mjx-c.mjx-c1D452.TEX-I::before{padding:.442em .466em .011em 0;content:"e"}mjx-c.mjx-c77::before{padding:.431em .722em .011em 0;content:"w"}mjx-mover{display:inline-block;text-align:left}mjx-mover:not([limits=false]){padding-top:.1em}mjx-mover:not([limits=false])>*{display:block;text-align:left}mjx-c.mjx-c5E::before{padding:.694em .5em 0 0;content:"^"}mjx-c.mjx-c210E.TEX-I::before{padding:.694em .576em .011em 0;content:"h"}mjx-c.mjx-c1D44E.TEX-I::before{padding:.441em .529em .01em 0;content:"a"}mjx-c.mjx-c1D461.TEX-I::before{padding:.626em .361em .011em 0;content:"t"}mjx-c.mjx-c24::before{padding:.75em .5em .056em 0;content:"$"}mjx-c.mjx-cA0::before{padding:0 .25em 0 0;content:" "}mjx-c.mjx-c62::before{padding:.694em .556em .011em 0;content:"b"}mjx-c.mjx-c76::before{padding:.431em .528em .011em 0;content:"v"}mjx-c.mjx-c52.TEX-C::before{padding:.682em .848em .022em 0;content:"R"}mjx-c.mjx-c6C::before{padding:.694em .278em 0 0;content:"l"}mjx-c.mjx-c63::before{padding:.448em .444em .011em 0;content:"c"}mjx-c.mjx-c68::before{padding:.694em .556em 0 0;content:"h"}mjx-c.mjx-c74::before{padding:.615em .389em .01em 0;content:"t"}mjx-c.mjx-c6D::before{padding:.442em .833em 0 0;content:"m"}mjx-c.mjx-c52::before{padding:.683em .736em .022em 0;content:"R"}mjx-c.mjx-c1D445.TEX-I::before{padding:.683em .759em .021em 0;content:"R"}mjx-c.mjx-c5C::before{padding:.75em .5em .25em 0;content:"\\"}mjx-c.mjx-c69::before{padding:.669em .278em 0 0;content:"i"}mjx-c.mjx-c1D466.TEX-I::before{padding:.442em .49em .205em 0;content:"y"}mjx-msqrt{display:inline-block;text-align:left}mjx-root{display:inline-block;white-space:nowrap}mjx-surd{display:inline-block;vertical-align:top}mjx-sqrt{display:inline-block;padding-top:.07em}mjx-sqrt>mjx-box{border-top:.07em solid}mjx-sqrt.mjx-tall>mjx-box{padding-left:.3em;margin-left:-.3em}mjx-msubsup{display:inline-block;text-align:left}mjx-script{display:inline-block;padding-right:.05em;padding-left:.033em}mjx-script>mjx-spacer{display:block}mjx-mrow{display:inline-block;text-align:left}mjx-mtable{display:inline-block;text-align:center;vertical-align:.25em;position:relative;box-sizing:border-box;border-spacing:0px;border-collapse:collapse}mjx-mstyle[size="s"] mjx-mtable{vertical-align:.354em}mjx-labels{position:absolute;left:0;top:0}mjx-table{display:inline-block;vertical-align:-.5ex;box-sizing:border-box}mjx-table>mjx-itable{vertical-align:middle;text-align:left;box-sizing:border-box}mjx-labels>mjx-itable{position:absolute;top:0}mjx-mtable[justify=left]{text-align:left}mjx-mtable[justify=right]{text-align:right}mjx-mtable[justify=left][side=left]{padding-right:0!important}mjx-mtable[justify=left][side=right]{padding-left:0!important}mjx-mtable[justify=right][side=left]{padding-right:0!important}mjx-mtable[justify=right][side=right]{padding-left:0!important}mjx-mtable[align]{vertical-align:baseline}mjx-mtable[align=top]>mjx-table{vertical-align:top}mjx-mtable[align=bottom]>mjx-table{vertical-align:bottom}mjx-mtable[side=right] mjx-labels{min-width:100%}mjx-mtr{display:table-row;text-align:left}mjx-mtr[rowalign=top]>mjx-mtd{vertical-align:top}mjx-mtr[rowalign=center]>mjx-mtd{vertical-align:middle}mjx-mtr[rowalign=bottom]>mjx-mtd{vertical-align:bottom}mjx-mtr[rowalign=baseline]>mjx-mtd{vertical-align:baseline}mjx-mtr[rowalign=axis]>mjx-mtd{vertical-align:.25em}mjx-mtd{display:table-cell;text-align:center;padding:.215em .4em}mjx-mtd:first-child{padding-left:0}mjx-mtd:last-child{padding-right:0}mjx-mtable>*>mjx-itable>:first-child>mjx-mtd{padding-top:0}mjx-mtable>*>mjx-itable>:last-child>mjx-mtd{padding-bottom:0}mjx-tstrut{display:inline-block;height:1em;vertical-align:-.25em}mjx-labels[align=left]>mjx-mtr>mjx-mtd{text-align:left}mjx-labels[align=right]>mjx-mtr>mjx-mtd{text-align:right}mjx-mtd[extra]{padding:0}mjx-mtd[rowalign=top]{vertical-align:top}mjx-mtd[rowalign=center]{vertical-align:middle}mjx-mtd[rowalign=bottom]{vertical-align:bottom}mjx-mtd[rowalign=baseline]{vertical-align:baseline}mjx-mtd[rowalign=axis]{vertical-align:.25em}mjx-stretchy-v.mjx-c5B mjx-beg mjx-c::before{content:"⎡";padding:1.154em .667em .645em 0}mjx-stretchy-v.mjx-c5B mjx-ext mjx-c::before{content:"⎢";width:.667em}mjx-stretchy-v.mjx-c5B mjx-end mjx-c::before{content:"⎣";padding:1.155em .667em .644em 0}mjx-stretchy-v.mjx-c5B>mjx-end{margin-top:-1.799em}mjx-stretchy-v.mjx-c5B>mjx-ext{border-top-width:1.769em;border-bottom-width:1.769em}mjx-stretchy-v.mjx-c5D mjx-beg mjx-c::before{content:"⎤";padding:1.154em .667em .645em 0}mjx-stretchy-v.mjx-c5D mjx-ext mjx-c::before{content:"⎥";width:.667em}mjx-stretchy-v.mjx-c5D mjx-end mjx-c::before{content:"⎦";padding:1.155em .667em .644em 0}mjx-stretchy-v.mjx-c5D>mjx-end{margin-top:-1.799em}mjx-stretchy-v.mjx-c5D>mjx-ext{border-top-width:1.769em;border-bottom-width:1.769em}mjx-c.mjx-c1D451.TEX-I::before{padding:.694em .52em .01em 0;content:"d"}mjx-c.mjx-c1D45A.TEX-I::before{padding:.442em .878em .011em 0;content:"m"}mjx-c.mjx-cD7::before{padding:.491em .778em 0 0;content:"×"}mjx-c.mjx-c2264::before{padding:.636em .778em .138em 0;content:"≤"}mjx-c.mjx-c2225::before{padding:.75em .5em .25em 0;content:"∥"}mjx-c.mjx-c221A.TEX-S2::before{padding:1.15em 1.02em .65em 0;content:"√"}mjx-c.mjx-c1D463.TEX-I::before{padding:.443em .485em .011em 0;content:"v"}mjx-c.mjx-c1D430.TEX-B::before{padding:.444em .831em 0 0;content:"w"}mjx-c.mjx-c2212::before{padding:.583em .778em .082em 0;content:"−"}mjx-c.mjx-c5B::before{padding:.75em .278em .25em 0;content:"["}mjx-c.mjx-c5D::before{padding:.75em .278em .25em 0;content:"]"}mjx-c.mjx-c5B.TEX-S3::before{padding:1.45em .528em .949em 0;content:"["}mjx-c.mjx-c1D462.TEX-I::before{padding:.442em .572em .011em 0;content:"u"}mjx-c.mjx-c5D.TEX-S3::before{padding:1.45em .528em .949em 0;content:"]"}mjx-c.mjx-c22C5::before{padding:.31em .278em 0 0;content:"⋅"}mjx-container[jax=CHTML]{line-height:0}mjx-container [space="1"]{margin-left:.111em}mjx-container [space="2"]{margin-left:.167em}mjx-container [space="3"]{margin-left:.222em}mjx-container [space="4"]{margin-left:.278em}mjx-container [space="5"]{margin-left:.333em}mjx-container [rspace="1"]{margin-right:.111em}mjx-container [rspace="2"]{margin-right:.167em}mjx-container [rspace="3"]{margin-right:.222em}mjx-container [rspace="4"]{margin-right:.278em}mjx-container [rspace="5"]{margin-right:.333em}mjx-container [size="s"]{font-size:70.7%}mjx-container [size=ss]{font-size:50%}mjx-container [size=Tn]{font-size:60%}mjx-container [size=sm]{font-size:85%}mjx-container [size=lg]{font-size:120%}mjx-container [size=Lg]{font-size:144%}mjx-container [size=LG]{font-size:173%}mjx-container [size=hg]{font-size:207%}mjx-container [size=HG]{font-size:249%}mjx-container [width=full]{width:100%}mjx-box{display:inline-block}mjx-block{display:block}mjx-itable{display:inline-table}mjx-row{display:table-row}mjx-row>*{display:table-cell}mjx-mtext{display:inline-block;text-align:left}mjx-mstyle{display:inline-block}mjx-merror{display:inline-block;color:red;background-color:#ff0}mjx-mphantom{visibility:hidden}mjx-assistive-mml{top:0;left:0;clip:rect(1px,1px,1px,1px);user-select:none;position:absolute!important;padding:1px 0 0!important;border:0!important;display:block!important;width:auto!important;overflow:hidden!important}mjx-assistive-mml[display=block]{width:100%!important}mjx-math{display:inline-block;text-align:left;line-height:0;text-indent:0;font-style:normal;font-weight:400;font-size:100%;font-size-adjust:none;letter-spacing:normal;border-collapse:collapse;overflow-wrap:normal;word-spacing:normal;white-space:nowrap;direction:ltr;padding:1px 0}mjx-container[jax=CHTML][display=true]{display:block;text-align:center;margin:1em 0}mjx-container[jax=CHTML][display=true][width=full]{display:flex}mjx-container[jax=CHTML][display=true] mjx-math{padding:0}mjx-container[jax=CHTML][justify=left]{text-align:left}mjx-container[jax=CHTML][justify=right]{text-align:right}mjx-mo{display:inline-block;text-align:left}mjx-stretchy-h{display:inline-table;width:100%}mjx-stretchy-h>*{display:table-cell;width:0}mjx-stretchy-h>*>mjx-c{display:inline-block;transform:scaleX(1)}mjx-stretchy-h>*>mjx-c::before{display:inline-block;width:initial}mjx-stretchy-h>mjx-ext{overflow:clip visible;width:100%}mjx-stretchy-h>mjx-ext>mjx-c::before{transform:scaleX(500)}mjx-stretchy-h>mjx-ext>mjx-c{width:0}mjx-stretchy-h>mjx-beg>mjx-c{margin-right:-.1em}mjx-stretchy-h>mjx-end>mjx-c{margin-left:-.1em}mjx-stretchy-v{display:inline-block}mjx-stretchy-v>*{display:block}mjx-stretchy-v>mjx-beg{height:0}mjx-stretchy-v>mjx-end>mjx-c{display:block}mjx-stretchy-v>*>mjx-c{transform:scaleY(1);transform-origin:left center;overflow:hidden}mjx-stretchy-v>mjx-ext{display:block;height:100%;box-sizing:border-box;border:0 solid transparent;overflow:visible clip}mjx-stretchy-v>mjx-ext>mjx-c::before{width:initial;box-sizing:border-box}mjx-stretchy-v>mjx-ext>mjx-c{transform:scaleY(500) translateY(.075em);overflow:visible}mjx-mark{display:inline-block;height:0}mjx-c{display:inline-block}mjx-utext{display:inline-block;padding:.75em 0 .2em}mjx-msub{display:inline-block;text-align:left}mjx-texatom{display:inline-block;text-align:left}mjx-mi{display:inline-block;text-align:left}mjx-mn{display:inline-block;text-align:left}mjx-msup{display:inline-block;text-align:left}mjx-mspace{display:inline-block;text-align:left}mjx-c::before{display:block;width:0}.MJX-TEX{font-family:MJXZERO,MJXTEX}.TEX-B{font-family:MJXZERO,MJXTEX-B}.TEX-I{font-family:MJXZERO,MJXTEX-I}.TEX-MI{font-family:MJXZERO,MJXTEX-MI}.TEX-BI{font-family:MJXZERO,MJXTEX-BI}.TEX-S1{font-family:MJXZERO,MJXTEX-S1}.TEX-S2{font-family:MJXZERO,MJXTEX-S2}.TEX-S3{font-family:MJXZERO,MJXTEX-S3}.TEX-S4{font-family:MJXZERO,MJXTEX-S4}.TEX-A{font-family:MJXZERO,MJXTEX-A}.TEX-C{font-family:MJXZERO,MJXTEX-C}.TEX-CB{font-family:MJXZERO,MJXTEX-CB}.TEX-FR{font-family:MJXZERO,MJXTEX-FR}.TEX-FRB{font-family:MJXZERO,MJXTEX-FRB}.TEX-SS{font-family:MJXZERO,MJXTEX-SS}.TEX-SSB{font-family:MJXZERO,MJXTEX-SSB}.TEX-SSI{font-family:MJXZERO,MJXTEX-SSI}.TEX-SC{font-family:MJXZERO,MJXTEX-SC}.TEX-T{font-family:MJXZERO,MJXTEX-T}.TEX-V{font-family:MJXZERO,MJXTEX-V}.TEX-VB{font-family:MJXZERO,MJXTEX-VB}mjx-stretchy-h mjx-c,mjx-stretchy-v mjx-c{font-family:MJXZERO,MJXTEX-S1,MJXTEX-S4,MJXTEX,MJXTEX-A!important}@font-face{font-family:MJXZERO;src:url("site-lib/fonts/mathjax_zero.woff") format("woff")}@font-face{font-family:MJXTEX;src:url("site-lib/fonts/mathjax_main-regular.woff") format("woff")}@font-face{font-family:MJXTEX-B;src:url("site-lib/fonts/mathjax_main-bold.woff") format("woff")}@font-face{font-family:MJXTEX-I;src:url("site-lib/fonts/mathjax_math-italic.woff") format("woff")}@font-face{font-family:MJXTEX-MI;src:url("site-lib/fonts/mathjax_main-italic.woff") format("woff")}@font-face{font-family:MJXTEX-BI;src:url("site-lib/fonts/mathjax_math-bolditalic.woff") format("woff")}@font-face{font-family:MJXTEX-S1;src:url("site-lib/fonts/mathjax_size1-regular.woff") format("woff")}@font-face{font-family:MJXTEX-S2;src:url("site-lib/fonts/mathjax_size2-regular.woff") format("woff")}@font-face{font-family:MJXTEX-S3;src:url("site-lib/fonts/mathjax_size3-regular.woff") format("woff")}@font-face{font-family:MJXTEX-S4;src:url("site-lib/fonts/mathjax_size4-regular.woff") format("woff")}@font-face{font-family:MJXTEX-A;src:url("site-lib/fonts/mathjax_ams-regular.woff") format("woff")}@font-face{font-family:MJXTEX-C;src:url("site-lib/fonts/mathjax_calligraphic-regular.woff") format("woff")}@font-face{font-family:MJXTEX-CB;src:url("site-lib/fonts/mathjax_calligraphic-bold.woff") format("woff")}@font-face{font-family:MJXTEX-FR;src:url("site-lib/fonts/mathjax_fraktur-regular.woff") format("woff")}@font-face{font-family:MJXTEX-FRB;src:url("site-lib/fonts/mathjax_fraktur-bold.woff") format("woff")}@font-face{font-family:MJXTEX-SS;src:url("site-lib/fonts/mathjax_sansserif-regular.woff") format("woff")}@font-face{font-family:MJXTEX-SSB;src:url("site-lib/fonts/mathjax_sansserif-bold.woff") format("woff")}@font-face{font-family:MJXTEX-SSI;src:url("site-lib/fonts/mathjax_sansserif-italic.woff") format("woff")}@font-face{font-family:MJXTEX-SC;src:url("site-lib/fonts/mathjax_script-regular.woff") format("woff")}@font-face{font-family:MJXTEX-T;src:url("site-lib/fonts/mathjax_typewriter-regular.woff") format("woff")}@font-face{font-family:MJXTEX-V;src:url("site-lib/fonts/mathjax_vector-regular.woff") format("woff")}@font-face{font-family:MJXTEX-VB;src:url("site-lib/fonts/mathjax_vector-bold.woff") format("woff")}mjx-c.mjx-c7B::before{padding:.75em .5em .25em 0;content:"{"}mjx-c.mjx-c1D42F.TEX-B::before{padding:.444em .607em 0 0;content:"v"}mjx-c.mjx-c31::before{padding:.666em .5em 0 0;content:"1"}mjx-c.mjx-c2C::before{padding:.121em .278em .194em 0;content:","}mjx-c.mjx-c32::before{padding:.666em .5em 0 0;content:"2"}mjx-c.mjx-c2026::before{padding:.12em 1.172em 0 0;content:"…"}mjx-c.mjx-c1D458.TEX-I::before{padding:.694em .521em .011em 0;content:"k"}mjx-c.mjx-c7D::before{padding:.75em .5em .25em 0;content:"}"}mjx-c.mjx-c53::before{padding:.705em .556em .022em 0;content:"S"}mjx-c.mjx-c70::before{padding:.442em .556em .194em 0;content:"p"}mjx-c.mjx-c61::before{padding:.448em .5em .011em 0;content:"a"}mjx-c.mjx-c6E::before{padding:.442em .556em 0 0;content:"n"}mjx-c.mjx-c28::before{padding:.75em .389em .25em 0;content:"("}mjx-c.mjx-c29::before{padding:.75em .389em .25em 0;content:")"}mjx-c.mjx-c3D::before{padding:.583em .778em .082em 0;content:"="}mjx-c.mjx-c1D450.TEX-I::before{padding:.442em .433em .011em 0;content:"c"}mjx-c.mjx-c2B::before{padding:.583em .778em .082em 0;content:"+"}mjx-c.mjx-c22EF::before{padding:.31em 1.172em 0 0;content:"⋯"}mjx-c.mjx-c2223::before{padding:.75em .278em .249em 0;content:"∣"}mjx-c.mjx-c2208::before{padding:.54em .667em .04em 0;content:"∈"}mjx-c.mjx-c211D.TEX-A::before{padding:.683em .722em 0 0;content:"R"}mjx-c.mjx-c2E::before{padding:.12em .278em 0 0;content:"."}mjx-c.mjx-c1D7CE.TEX-B::before{padding:.654em .575em .01em 0;content:"0"}mjx-c.mjx-c30::before{padding:.666em .5em .022em 0;content:"0"}mjx-c.mjx-c1D456.TEX-I::before{padding:.661em .345em .011em 0;content:"i"}mjx-c.mjx-c1D449.TEX-I::before{padding:.683em .769em .022em 0;content:"V"}mjx-c.mjx-c1D45B.TEX-I::before{padding:.442em .6em .011em 0;content:"n"}mjx-c.mjx-c33::before{padding:.665em .5em .022em 0;content:"3"}mjx-c.mjx-c1D44A.TEX-I::before{padding:.683em 1.048em .022em 0;content:"W"}mjx-c.mjx-c1D42E.TEX-B::before{padding:.45em .639em .006em 0;content:"u"}mjx-c.mjx-c27F9::before{padding:.525em 1.638em .024em 0;content:"⟹"}mjx-c.mjx-c2286::before{padding:.636em .778em .138em 0;content:"⊆"}</style><pre class="frontmatter language-yaml" style="display: none;"><code class="language-yaml is-loaded"><span class="token key atrule">title</span><span class="token punctuation">:</span> <span class="token string">"HuggingFace: LLM Course"</span>
<span class="token key atrule">tags</span><span class="token punctuation">:</span>
  <span class="token punctuation">-</span> HuggingFace
  <span class="token punctuation">-</span> LLMs
  <span class="token punctuation">-</span> Course</code><button class="copy-code-button"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon lucide-copy"><rect x="8" y="8" width="14" height="14" rx="2" ry="2"></rect><path d="M4 16c-1.1 0-2-.9-2-2V4c0-1.1.9-2 2-2h10c1.1 0 2 .9 2 2"></path></svg></button></pre><div class="markdown-preview-sizer markdown-preview-section"><div class="header"><h1 class="page-title heading inline-title" id="HuggingFace_LLM_Course_0">HuggingFace: LLM Course</h1><div class="data-bar"></div></div><div class="markdown-preview-pusher" style="width: 1px; height: 0.1px; margin-bottom: 0px;"></div><div class="el-h2"><h2 data-heading="0. SETUP" dir="auto" class="heading" id="0._SETUP_0"><span class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></span>0. SETUP</h2></div><div class="el-h3"><h3 data-heading="Commonly used libraries" dir="auto" class="heading" id="Commonly_used_libraries_0"><span class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></span>Commonly used libraries</h3></div><div class="el-ul"><ul class="has-list-bullet">
<li data-line="0" dir="auto"><span class="list-bullet"></span>transformers</li>
<li data-line="1" dir="auto"><span class="list-bullet"></span>datasets</li>
<li data-line="2" dir="auto"><span class="list-bullet"></span>torch</li>
</ul></div><div class="el-h2"><h2 data-heading="1. TRANSFORMER MODELS" dir="auto" class="heading" id="1._TRANSFORMER_MODELS_0"><span class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></span>1. TRANSFORMER MODELS</h2></div><div class="el-h3"><h3 data-heading="Pipeline() Function" dir="auto" class="heading" id="Pipeline()_Function_0"><span class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></span>Pipeline() Function</h3></div><div class="el-p"><p dir="auto">The&nbsp;<code>pipeline()</code>&nbsp;function in the 🤗 Transformers library simplifies using models by integrating preprocessing and postprocessing steps.</p></div><div class="el-pre"><pre class="language-python"><code data-line="0" class="language-python is-loaded"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> pipeline

text <span class="token operator">=</span> <span class="token string">"Huggingface is awesome!"</span>

<span class="token comment"># sentiment analysis:</span>
e2e_model <span class="token operator">=</span> pipeline<span class="token punctuation">(</span><span class="token string">"sentiment-analysis"</span><span class="token punctuation">)</span>
e2e_model<span class="token punctuation">(</span>text<span class="token punctuation">)</span>
</code><button class="copy-code-button"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon lucide-copy"><rect x="8" y="8" width="14" height="14" rx="2" ry="2"></rect><path d="M4 16c-1.1 0-2-.9-2-2V4c0-1.1.9-2 2-2h10c1.1 0 2 .9 2 2"></path></svg></button></pre></div><div class="el-div"><div data-callout-metadata="" data-callout-fold="" data-callout="tip" class="callout"><div class="callout-title" dir="auto"><div class="callout-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon lucide-flame"><path d="M8.5 14.5A2.5 2.5 0 0 0 11 12c0-1.38-.5-2-1-3-1.072-2.143-.224-4.054 2-6 .5 2.5 2 4.9 4 6.5 2 1.6 3 3.5 3 5.5a7 7 0 1 1-14 0c0-1.153.433-2.294 1-3a2.5 2.5 0 0 0 2.5 2.5z"></path></svg></div><div class="callout-title-inner">Tip</div></div><div class="callout-content">
<p dir="auto">We can pass several sentences in one go!</p>
</div></div></div><div class="el-pre"><pre class="language-python"><code data-line="0" class="language-python is-loaded">e2e_model<span class="token punctuation">(</span><span class="token punctuation">[</span>
	<span class="token string">"I've been waiting for a HuggingFace course my whole life."</span><span class="token punctuation">,</span> 
	<span class="token string">"I hate this so much!"</span>
<span class="token punctuation">]</span><span class="token punctuation">)</span>
</code><button class="copy-code-button"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon lucide-copy"><rect x="8" y="8" width="14" height="14" rx="2" ry="2"></rect><path d="M4 16c-1.1 0-2-.9-2-2V4c0-1.1.9-2 2-2h10c1.1 0 2 .9 2 2"></path></svg></button></pre></div><div class="el-h3"><h3 data-heading="Tasks and Pipeline() Compatibility" dir="auto" class="heading" id="Tasks_and_Pipeline()_Compatibility_0"><span class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></span>Tasks and Pipeline() Compatibility</h3></div><div class="el-ul"><ul class="has-list-bullet">
<li data-line="0" dir="auto"><span class="list-bullet"></span><strong>NLP Pipelines</strong></li>
</ul></div><div class="el-table" dir="ltr" style="overflow-x: auto;"><table>
<thead>
<tr>
<th dir="ltr"><strong>Task</strong></th>
<th dir="ltr"><strong>Description</strong></th>
<th dir="ltr"><strong>Pipeline()</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td dir="ltr">feature-extraction</td>
<td dir="ltr">Extract vector representations of text.</td>
<td dir="auto">✓</td>
</tr>
<tr>
<td dir="ltr">fill-mask</td>
<td dir="ltr">Fills masked text data.</td>
<td dir="auto">✓</td>
</tr>
<tr>
<td dir="ltr">question-answering</td>
<td dir="ltr">Retrieve the answer to a question from a given text.</td>
<td dir="auto">✓</td>
</tr>
<tr>
<td dir="ltr">sentence-similarity</td>
<td dir="ltr">Determine how similar two texts are.</td>
<td dir="auto">✗</td>
</tr>
<tr>
<td dir="ltr">summarization</td>
<td dir="ltr">Create a shorter version of a text while preserving key information.</td>
<td dir="auto">✓</td>
</tr>
<tr>
<td dir="ltr">table-question-answering</td>
<td dir="ltr">Answering a question about an information on a given table.</td>
<td dir="auto">✓</td>
</tr>
<tr>
<td dir="ltr">text-classification</td>
<td dir="ltr">Classify text into predefined categories.</td>
<td dir="auto">✓</td>
</tr>
<tr>
<td dir="ltr">text-generation</td>
<td dir="ltr">Generate text from a prompt.</td>
<td dir="auto">✓</td>
</tr>
<tr>
<td dir="ltr">text-ranking</td>
<td dir="ltr">Rank a set of texts based on their relevance to a query.</td>
<td dir="auto">✗</td>
</tr>
<tr>
<td dir="ltr">token-classification</td>
<td dir="ltr">NLU task in which a label is assigned to some tokens in a text.</td>
<td dir="auto">✓</td>
</tr>
<tr>
<td dir="ltr">translation</td>
<td dir="ltr">Convert text from one language to another.</td>
<td dir="auto">✓</td>
</tr>
<tr>
<td dir="ltr">zero-shot-classification</td>
<td dir="ltr">Classify text without prior training on specific labels.</td>
<td dir="auto">✓</td>
</tr>
</tbody>
</table></div><div class="el-ul"><ul class="has-list-bullet">
<li data-line="0" dir="auto"><span class="list-bullet"></span><strong>Vision pipelines</strong></li>
</ul></div><div class="el-table" dir="ltr" style="overflow-x: auto;"><table>
<thead>
<tr>
<th dir="ltr"><strong>Task</strong></th>
<th dir="ltr"><strong>Description</strong></th>
<th dir="ltr">Pipeline()</th>
</tr>
</thead>
<tbody>
<tr>
<td dir="ltr">depth-estimation</td>
<td dir="ltr">Estimate the depth of different objects present in an image.</td>
<td dir="auto">✓</td>
</tr>
<tr>
<td dir="ltr">image-classification</td>
<td dir="ltr">Identify objects in an image.</td>
<td dir="auto">✓</td>
</tr>
<tr>
<td dir="ltr">image-feature-extraction</td>
<td dir="ltr">Extract semantically meaningful features given an image.</td>
<td dir="auto">✓</td>
</tr>
<tr>
<td dir="ltr">image-segmentation</td>
<td dir="ltr">Divides an image into segments where each pixel in the image is mapped to an object</td>
<td dir="auto">✓</td>
</tr>
<tr>
<td dir="ltr">image-to-image</td>
<td dir="ltr">Transform image. (eg. inpainting, colorization, Super Resolution)</td>
<td dir="auto">✓</td>
</tr>
<tr>
<td dir="ltr">image-to-text</td>
<td dir="ltr">Generate text descriptions of images.</td>
<td dir="auto">✓</td>
</tr>
<tr>
<td dir="ltr">image-to-video</td>
<td dir="ltr">Generate a video influenced by text prompts.</td>
<td dir="auto">✗</td>
</tr>
<tr>
<td dir="ltr">keypoint-detection</td>
<td dir="ltr">Identify meaningful distinctive points or features in an image.</td>
<td dir="auto">✗</td>
</tr>
<tr>
<td dir="ltr">mask-generation</td>
<td dir="ltr">Generate masks that identify a specific object or region of interest in a given image.</td>
<td dir="auto">✓</td>
</tr>
<tr>
<td dir="ltr">object-detection</td>
<td dir="ltr">Locate and identify objects in images.</td>
<td dir="auto">✓</td>
</tr>
<tr>
<td dir="ltr">video-classification</td>
<td dir="ltr">Assign a label or class to an entire video.</td>
<td dir="auto">✓</td>
</tr>
<tr>
<td dir="ltr">text-to-image</td>
<td dir="ltr">Generating images from input text.</td>
<td dir="auto">✗</td>
</tr>
<tr>
<td dir="ltr">text-to-video</td>
<td dir="ltr">Generating consistent sequence of images from text.</td>
<td dir="auto">✗</td>
</tr>
<tr>
<td dir="ltr">unconditional-image-generation</td>
<td dir="ltr">Generating images with no condition in any context.</td>
<td dir="auto">✗</td>
</tr>
<tr>
<td dir="ltr">video-to-video</td>
<td dir="ltr">Transform input video into a new video with altered visual styles, motion, or content.</td>
<td dir="auto">✗</td>
</tr>
<tr>
<td dir="ltr">zero-shot-image-classification</td>
<td dir="ltr">Classify previously unseen classes during training of a model.</td>
<td dir="auto">✓</td>
</tr>
<tr>
<td dir="ltr">zero-shot-object-detection</td>
<td dir="ltr">Detect objects and their classes in images, without any prior training or knowledge of the classes.</td>
<td dir="auto">✓</td>
</tr>
<tr>
<td dir="ltr">text-to-3d</td>
<td dir="ltr">Text-to-3D models take in text input and produce 3D output.</td>
<td dir="auto">✗</td>
</tr>
<tr>
<td dir="ltr">image-to-3d</td>
<td dir="ltr">Image-to-3D models take in image input and produce 3D output.</td>
<td dir="auto">✗</td>
</tr>
</tbody>
</table></div><div class="el-ul"><ul class="has-list-bullet">
<li data-line="0" dir="auto"><span class="list-bullet"></span><strong>Audio pipelines</strong></li>
</ul></div><div class="el-table" dir="ltr" style="overflow-x: auto;"><table>
<thead>
<tr>
<th dir="ltr"><strong>Task</strong></th>
<th dir="ltr"><strong>Description</strong></th>
<th dir="ltr"><strong>Pipeline()</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td dir="ltr">audio-classification</td>
<td dir="ltr">Classify audio into categories.</td>
<td dir="auto">✓</td>
</tr>
<tr>
<td dir="ltr">audio-to-audio</td>
<td dir="ltr">family of tasks in which the input is an audio and the output is one or multiple generated audios. (eg. speech enhancement, source separation, ...)</td>
<td dir="auto">✗</td>
</tr>
<tr>
<td dir="ltr">automatic-speech-recognition</td>
<td dir="ltr">Convert speech to text.</td>
<td dir="auto">✓</td>
</tr>
<tr>
<td dir="ltr">text-to-audio</td>
<td dir="ltr">Convert text to spoken audio.</td>
<td dir="auto">✓</td>
</tr>
</tbody>
</table></div><div class="el-ul"><ul class="has-list-bullet">
<li data-line="0" dir="auto"><span class="list-bullet"></span><strong>Multimodal pipelines</strong></li>
</ul></div><div class="el-table" dir="ltr" style="overflow-x: auto;"><table>
<thead>
<tr>
<th dir="ltr"><strong>Task</strong></th>
<th dir="ltr"><strong>Description</strong></th>
<th dir="ltr"><strong>Pipeline()</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td dir="ltr">any-to-any</td>
<td dir="ltr">Understand two or more modalities and output two or more modalities.</td>
<td dir="auto">✗</td>
</tr>
<tr>
<td dir="ltr">audio-text-to-text</td>
<td dir="ltr">Generate textual responses or summaries based on both audio input and text prompts.</td>
<td dir="auto">✗</td>
</tr>
<tr>
<td dir="ltr">document-question-answering</td>
<td dir="ltr">Take a (document, question) pair as input and return an answer in natural language.</td>
<td dir="auto">✗</td>
</tr>
<tr>
<td dir="ltr">visual-document-retrieval</td>
<td dir="ltr">Searching for relevant image-based documents, such as PDFs based on input text prompt.</td>
<td dir="auto">✓</td>
</tr>
<tr>
<td dir="ltr">image-text-to-text</td>
<td dir="ltr">Take in an image and text prompt and output text.</td>
<td dir="auto">✓</td>
</tr>
<tr>
<td dir="ltr">video-text-to-text</td>
<td dir="ltr">Take in a video and a text prompt and output text.</td>
<td dir="auto">✗</td>
</tr>
<tr>
<td dir="ltr">visual-question-answering</td>
<td dir="ltr">Answering open-ended questions based on an image depending on text prompt.</td>
<td dir="auto">✓</td>
</tr>
</tbody>
</table></div><div class="el-h3"><h3 data-heading="Classification of LLM Models" dir="auto" class="heading" id="Classification_of_LLM_Models_0"><span class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></span>Classification of LLM Models</h3></div><div class="el-h4"><h4 data-heading="1: Encoder Based (Auto-Encoding Transformers)" dir="auto" class="heading" id="1_Encoder_Based_(Auto-Encoding_Transformers)_0"><span class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></span>1: Encoder Based (Auto-Encoding Transformers)</h4></div><div class="el-ul"><ul class="has-list-bullet">
<li data-line="0" dir="auto"><span class="list-bullet"></span><strong>Focus:</strong>&nbsp;Understanding context, generating embeddings.</li>
<li data-line="1" dir="auto"><span class="list-bullet"></span><strong>Mechanism:</strong>&nbsp;Bidirectional attention (sees past &amp; future tokens).</li>
<li data-line="2" dir="auto"><span class="list-bullet"></span><strong>Training:</strong>&nbsp;Masked Language Modeling (MLM).</li>
<li data-line="3" dir="auto"><span class="list-bullet"></span><strong>Use Cases:</strong>&nbsp;Text classification, sentiment analysis, Named Entity Recognition (NER), question answering (understanding).</li>
<li data-line="4" dir="auto"><span class="list-bullet"></span><strong>Examples:</strong>&nbsp;BERT, RoBERTa.</li>
</ul></div><div class="el-h4"><h4 data-heading="2: Decoder Based (Auto-Regressive Transformers)" dir="auto" class="heading" id="2_Decoder_Based_(Auto-Regressive_Transformers)_0"><span class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></span>2: Decoder Based (Auto-Regressive Transformers)</h4></div><div class="el-ul"><ul class="has-list-bullet">
<li data-line="0" dir="auto"><span class="list-bullet"></span><strong>Focus:</strong>&nbsp;Generating new text, predicting next token.</li>
<li data-line="1" dir="auto"><span class="list-bullet"></span><strong>Mechanism:</strong>&nbsp;Unidirectional attention (sees only past tokens).</li>
<li data-line="2" dir="auto"><span class="list-bullet"></span><strong>Training:</strong>&nbsp;Predicts next word in a sequence.</li>
<li data-line="3" dir="auto"><span class="list-bullet"></span><strong>Use Cases:</strong>&nbsp;Text generation, summarization, chatbots, code generation.</li>
<li data-line="4" dir="auto"><span class="list-bullet"></span><strong>Examples:</strong>&nbsp;GPT series, LLaMA, Claude.</li>
</ul></div><div class="el-h4"><h4 data-heading="3: Encoder + Decoder Based Transformers" dir="auto" class="heading" id="3_Encoder_+_Decoder_Based_Transformers_0"><span class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></span>3: Encoder + Decoder Based Transformers</h4></div><div class="el-ul"><ul class="has-list-bullet">
<li data-line="0" dir="auto"><span class="list-bullet"></span><strong>Focus:</strong>&nbsp;Transforming one sequence into another.</li>
<li data-line="1" dir="auto"><span class="list-bullet"></span><strong>Mechanism:</strong>&nbsp;Encoder-Decoder architecture. Encoder processes input, Decoder generates output having influenced by input.</li>
<li data-line="2" dir="auto"><span class="list-bullet"></span><strong>Training:</strong>&nbsp;Maps input sequence to output sequence.</li>
<li data-line="3" dir="auto"><span class="list-bullet"></span><strong>Use Cases:</strong>&nbsp;Machine translation, abstractive summarization, text style transfer.</li>
<li data-line="4" dir="auto"><span class="list-bullet"></span><strong>Examples:</strong>&nbsp;T5, BART, NMT models.</li>
</ul></div><div class="el-h3"><h3 data-heading="Auto-Encoding Models" dir="auto" class="heading" id="Auto-Encoding_Models_0"><span class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></span>Auto-Encoding Models</h3></div><div class="el-h4"><h4 data-heading="Model: BaseAutoEncodingModel" dir="auto" class="heading" id="Model_BaseAutoEncodingModel_0"><span class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></span>Model: BaseAutoEncodingModel</h4></div><div class="el-pre"><pre class="language-python"><code data-line="0" class="language-python is-loaded"><span class="token comment"># Model: BaseAutoEncodingModel</span>
BaseAutoEncodingModel<span class="token punctuation">(</span>
	<span class="token string">'embedder'</span><span class="token punctuation">:</span> BaseAutoEncodingModelEmbedderModule<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
	<span class="token string">'encoder'</span><span class="token punctuation">:</span> BaseAutoEncodingModelEncoderModule<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
	<span class="token string">'pooler'</span><span class="token punctuation">:</span> BaseAutoEncodingModelPoolerModule<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span>
<span class="token punctuation">)</span>
</code><button class="copy-code-button"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon lucide-copy"><rect x="8" y="8" width="14" height="14" rx="2" ry="2"></rect><path d="M4 16c-1.1 0-2-.9-2-2V4c0-1.1.9-2 2-2h10c1.1 0 2 .9 2 2"></path></svg></button></pre></div><div class="el-h4"><h4 data-heading="Module: BaseAutoEncodingModelEmbedder" dir="auto" class="heading" id="Module_BaseAutoEncodingModelEmbedder_0"><span class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></span>Module: BaseAutoEncodingModelEmbedder</h4></div><div class="el-pre"><pre class="language-python"><code data-line="0" class="language-python is-loaded"><span class="token comment"># Module: BaseAutoEncodingModelEmbedder</span>
BaseAutoEncodingModelEmbedder<span class="token punctuation">(</span>
    <span class="token string">'word_emb'</span><span class="token punctuation">:</span> WordEmbedder<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token punctuation">,</span> 
    <span class="token string">'pos_emb'</span><span class="token punctuation">:</span> PositionEmbedder<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token punctuation">,</span> 
    <span class="token string">'tok_type_emb'</span><span class="token punctuation">:</span> TokenTypeEmbedder<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token punctuation">,</span> 
    <span class="token string">'layer_norm'</span><span class="token punctuation">:</span> LayerNorm<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token punctuation">,</span> 
    <span class="token string">'dropout'</span><span class="token punctuation">:</span> Dropout<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span>
<span class="token punctuation">)</span>
</code><button class="copy-code-button"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon lucide-copy"><rect x="8" y="8" width="14" height="14" rx="2" ry="2"></rect><path d="M4 16c-1.1 0-2-.9-2-2V4c0-1.1.9-2 2-2h10c1.1 0 2 .9 2 2"></path></svg></button></pre></div><div class="el-h4"><h4 data-heading="Module: BaseAutoEncodingModelEncoder" dir="auto" class="heading" id="Module_BaseAutoEncodingModelEncoder_0"><span class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></span>Module: BaseAutoEncodingModelEncoder</h4></div><div class="el-pre"><pre class="language-python"><code data-line="0" class="language-python is-loaded"><span class="token comment"># Module: BaseAutoEncodingModelEncoder</span>
BaseAutoEncodingModelEncoder<span class="token punctuation">(</span>
    <span class="token string">'layers'</span><span class="token punctuation">:</span> ModuleList<span class="token punctuation">(</span>
		<span class="token string">'layer'</span><span class="token punctuation">:</span> N x BaseAutoEncodingModelEncoderLayer<span class="token punctuation">(</span>
		    <span class="token string">'attention'</span><span class="token punctuation">:</span> BaseAutoEncodingModelAttention<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token punctuation">,</span> 
	        <span class="token string">'intermediate'</span><span class="token punctuation">:</span> BaseAutoEncodingModelIntermediate<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token punctuation">,</span> 
	        <span class="token string">'output'</span><span class="token punctuation">:</span> BaseAutoEncodingModelOutput<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span>
		<span class="token punctuation">)</span>
	<span class="token punctuation">)</span>
<span class="token punctuation">)</span>

<span class="token comment"># SubModule: BaseAutoEncodingModelAttention</span>
BaseAutoEncodingModelAttention<span class="token punctuation">(</span>
	<span class="token string">'self_attention'</span><span class="token punctuation">:</span> BaseAutoEncodingModelSelfAttention<span class="token punctuation">(</span>
		<span class="token string">'Q'</span><span class="token punctuation">:</span> Linear<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token punctuation">,</span> 
		<span class="token string">'K'</span><span class="token punctuation">:</span> Linear<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token punctuation">,</span> 
		<span class="token string">'V'</span><span class="token punctuation">:</span> Linear<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token punctuation">,</span> 
		<span class="token string">'dropout'</span><span class="token punctuation">:</span> Dropout<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span>
	<span class="token punctuation">)</span><span class="token punctuation">,</span>
	<span class="token string">'self_output'</span><span class="token punctuation">:</span> BaseAutoEncodingModelSelfOutput<span class="token punctuation">(</span>
		<span class="token string">'dense'</span><span class="token punctuation">:</span> Linear<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token punctuation">,</span> 
		<span class="token string">'layer_norm'</span><span class="token punctuation">:</span> LayerNorm<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token punctuation">,</span> 
		<span class="token string">'dropout'</span><span class="token punctuation">:</span> Dropout<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span>
	<span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>

<span class="token comment"># SubModule: BaseAutoEncodingModelIntermediate</span>
BaseAutoEncodingModelIntermediate<span class="token punctuation">(</span>
	<span class="token string">'dense'</span><span class="token punctuation">:</span> Linear<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token punctuation">,</span> 
	<span class="token string">'activation'</span><span class="token punctuation">:</span> Activation<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span>
<span class="token punctuation">)</span>

<span class="token comment"># SubModule: BaseAutoEncodingModelOutput</span>
BaseAutoEncodingModelOutput<span class="token punctuation">(</span>
	<span class="token string">'dense'</span><span class="token punctuation">:</span> Linear<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token punctuation">,</span> 
	<span class="token string">'layer_norm'</span><span class="token punctuation">:</span> LayerNorm<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token punctuation">,</span> 
	<span class="token string">'dropout'</span><span class="token punctuation">:</span> Dropout<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span> 
<span class="token punctuation">)</span>
</code><button class="copy-code-button"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon lucide-copy"><rect x="8" y="8" width="14" height="14" rx="2" ry="2"></rect><path d="M4 16c-1.1 0-2-.9-2-2V4c0-1.1.9-2 2-2h10c1.1 0 2 .9 2 2"></path></svg></button></pre></div><div class="el-h4"><h4 data-heading="Module: BaseAutoEncodingModelPooler" dir="auto" class="heading" id="Module_BaseAutoEncodingModelPooler_0"><span class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></span>Module: BaseAutoEncodingModelPooler</h4></div><div class="el-pre"><pre class="language-python"><code data-line="0" class="language-python is-loaded">BaseAutoEncodingModelPooler<span class="token punctuation">(</span>
	<span class="token string">'dense'</span><span class="token punctuation">:</span> Linear<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token punctuation">,</span> 
	<span class="token string">'activation'</span><span class="token punctuation">:</span> Activation<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span>
<span class="token punctuation">)</span>
</code><button class="copy-code-button"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon lucide-copy"><rect x="8" y="8" width="14" height="14" rx="2" ry="2"></rect><path d="M4 16c-1.1 0-2-.9-2-2V4c0-1.1.9-2 2-2h10c1.1 0 2 .9 2 2"></path></svg></button></pre></div><div class="el-h2"><h2 data-heading="Train Sequence to Sequence Model" dir="auto" class="heading" id="Train_Sequence_to_Sequence_Model_0"><span class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></span>Train Sequence to Sequence Model</h2></div><div class="el-pre"><pre class="language-python"><code data-line="0" class="language-python is-loaded"><span class="token keyword">import</span> torch<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn
<span class="token keyword">import</span> transformers
<span class="token keyword">import</span> tokenizers
<span class="token keyword">import</span> torch
<span class="token keyword">import</span> os
<span class="token keyword">import</span> math
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> TensorDataset<span class="token punctuation">,</span> DataLoader
<span class="token keyword">from</span> tqdm <span class="token keyword">import</span> tqdm
<span class="token keyword">import</span> glob

<span class="token keyword">if</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>exists<span class="token punctuation">(</span><span class="token string">"tokenizer.json"</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    tokenizer <span class="token operator">=</span> tokenizers<span class="token punctuation">.</span>Tokenizer<span class="token punctuation">.</span>from_file<span class="token punctuation">(</span><span class="token string">"tokenizer.json"</span><span class="token punctuation">)</span>
<span class="token keyword">else</span><span class="token punctuation">:</span>
    tokenizer <span class="token operator">=</span> tokenizers<span class="token punctuation">.</span>SentencePieceUnigramTokenizer<span class="token punctuation">(</span><span class="token punctuation">)</span>

    tokenizer<span class="token punctuation">.</span>train<span class="token punctuation">(</span>
        files<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'./notebooks/processed.hi'</span><span class="token punctuation">,</span> <span class="token string">'./notebooks/processed.en'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        vocab_size<span class="token operator">=</span><span class="token number">8000</span><span class="token punctuation">,</span>
        show_progress<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
        special_tokens<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"[UNK]"</span><span class="token punctuation">,</span> <span class="token string">"[PAD]"</span><span class="token punctuation">,</span> <span class="token string">"[CLS]"</span><span class="token punctuation">,</span> <span class="token string">"[SEP]"</span><span class="token punctuation">,</span> <span class="token string">"[MASK]"</span><span class="token punctuation">]</span>
    <span class="token punctuation">)</span>
    tokenizer<span class="token punctuation">.</span>save<span class="token punctuation">(</span><span class="token string">"tokenizer.json"</span><span class="token punctuation">)</span>

unk_token_id <span class="token operator">=</span> tokenizer<span class="token punctuation">.</span>token_to_id<span class="token punctuation">(</span><span class="token string">"[UNK]"</span><span class="token punctuation">)</span>
pad_token_id <span class="token operator">=</span> tokenizer<span class="token punctuation">.</span>token_to_id<span class="token punctuation">(</span><span class="token string">"[PAD]"</span><span class="token punctuation">)</span>
cls_token_id <span class="token operator">=</span> tokenizer<span class="token punctuation">.</span>token_to_id<span class="token punctuation">(</span><span class="token string">"[CLS]"</span><span class="token punctuation">)</span>
sep_token_id <span class="token operator">=</span> tokenizer<span class="token punctuation">.</span>token_to_id<span class="token punctuation">(</span><span class="token string">"[SEP]"</span><span class="token punctuation">)</span>
mask_token_id <span class="token operator">=</span> tokenizer<span class="token punctuation">.</span>token_to_id<span class="token punctuation">(</span><span class="token string">"[MASK]"</span><span class="token punctuation">)</span>

<span class="token keyword">class</span> <span class="token class-name">TranslationModelConfig</span><span class="token punctuation">(</span>transformers<span class="token punctuation">.</span>PretrainedConfig<span class="token punctuation">)</span><span class="token punctuation">:</span>
    model_type <span class="token operator">=</span> <span class="token string">"translation-hi2en"</span>

    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>
            self<span class="token punctuation">,</span>
            vocab_size<span class="token operator">=</span><span class="token number">8000</span><span class="token punctuation">,</span>
            d_model<span class="token operator">=</span><span class="token number">512</span><span class="token punctuation">,</span>
            num_encoder_layers<span class="token operator">=</span><span class="token number">6</span><span class="token punctuation">,</span>
            num_decoder_layers<span class="token operator">=</span><span class="token number">6</span><span class="token punctuation">,</span>
            num_heads<span class="token operator">=</span><span class="token number">8</span><span class="token punctuation">,</span>
            dim_feedforward<span class="token operator">=</span><span class="token number">512</span><span class="token punctuation">,</span>
            dropout<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">,</span>
            pad_token_id<span class="token operator">=</span>pad_token_id<span class="token punctuation">,</span>
            eos_token_id<span class="token operator">=</span>sep_token_id<span class="token punctuation">,</span>
            decoder_start_token_id<span class="token operator">=</span>cls_token_id<span class="token punctuation">,</span>
            initializer_range<span class="token operator">=</span><span class="token number">0.02</span><span class="token punctuation">,</span>
            max_position_embeddings<span class="token operator">=</span><span class="token number">512</span><span class="token punctuation">,</span>
            <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span>pad_token_id<span class="token operator">=</span>pad_token_id<span class="token punctuation">,</span> eos_token_id<span class="token operator">=</span>eos_token_id<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>vocab_size <span class="token operator">=</span> vocab_size
        self<span class="token punctuation">.</span>d_model <span class="token operator">=</span> d_model
        self<span class="token punctuation">.</span>num_encoder_layers <span class="token operator">=</span> num_encoder_layers
        self<span class="token punctuation">.</span>num_decoder_layers <span class="token operator">=</span> num_decoder_layers
        self<span class="token punctuation">.</span>num_heads <span class="token operator">=</span> num_heads
        self<span class="token punctuation">.</span>dim_feedforward <span class="token operator">=</span> dim_feedforward
        self<span class="token punctuation">.</span>dropout <span class="token operator">=</span> dropout
        self<span class="token punctuation">.</span>decoder_start_token_id <span class="token operator">=</span> decoder_start_token_id
        self<span class="token punctuation">.</span>initializer_range <span class="token operator">=</span> initializer_range
        self<span class="token punctuation">.</span>max_position_embeddings <span class="token operator">=</span> max_position_embeddings


<span class="token keyword">class</span> <span class="token class-name">PositionalEncoding</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> d_model<span class="token punctuation">,</span> dropout <span class="token operator">=</span> <span class="token number">0.1</span><span class="token punctuation">,</span> max_len <span class="token operator">=</span> <span class="token number">5000</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>dropout <span class="token operator">=</span> nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>p<span class="token operator">=</span>dropout<span class="token punctuation">)</span>

        position <span class="token operator">=</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>max_len<span class="token punctuation">)</span><span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
        div_term <span class="token operator">=</span> torch<span class="token punctuation">.</span>exp<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> d_model<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token punctuation">(</span><span class="token operator">-</span>math<span class="token punctuation">.</span>log<span class="token punctuation">(</span><span class="token number">10000.0</span><span class="token punctuation">)</span> <span class="token operator">/</span> d_model<span class="token punctuation">)</span><span class="token punctuation">)</span>

        pe <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>max_len<span class="token punctuation">,</span> d_model<span class="token punctuation">)</span>
        pe<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>sin<span class="token punctuation">(</span>position <span class="token operator">*</span> div_term<span class="token punctuation">)</span>
        pe<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>cos<span class="token punctuation">(</span>position <span class="token operator">*</span> div_term<span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>register_buffer<span class="token punctuation">(</span><span class="token string">'pe'</span><span class="token punctuation">,</span> pe<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        seq_len <span class="token operator">=</span> x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
        x <span class="token operator">=</span> x <span class="token operator">+</span> self<span class="token punctuation">.</span>pe<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span>seq_len<span class="token punctuation">]</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>dropout<span class="token punctuation">(</span>x<span class="token punctuation">)</span>


<span class="token keyword">class</span> <span class="token class-name">TranslationModel</span><span class="token punctuation">(</span>transformers<span class="token punctuation">.</span>PreTrainedModel<span class="token punctuation">)</span><span class="token punctuation">:</span>

    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> config<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span>config<span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>cfg <span class="token operator">=</span> config

        self<span class="token punctuation">.</span>src_embedding <span class="token operator">=</span> nn<span class="token punctuation">.</span>Embedding<span class="token punctuation">(</span>config<span class="token punctuation">.</span>vocab_size<span class="token punctuation">,</span> config<span class="token punctuation">.</span>d_model<span class="token punctuation">,</span> padding_idx<span class="token operator">=</span>config<span class="token punctuation">.</span>pad_token_id<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>tgt_embedding <span class="token operator">=</span> nn<span class="token punctuation">.</span>Embedding<span class="token punctuation">(</span>config<span class="token punctuation">.</span>vocab_size<span class="token punctuation">,</span> config<span class="token punctuation">.</span>d_model<span class="token punctuation">,</span> padding_idx<span class="token operator">=</span>config<span class="token punctuation">.</span>pad_token_id<span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>positional_encoding <span class="token operator">=</span> PositionalEncoding<span class="token punctuation">(</span>config<span class="token punctuation">.</span>d_model<span class="token punctuation">,</span> config<span class="token punctuation">.</span>dropout<span class="token punctuation">,</span> config<span class="token punctuation">.</span>max_position_embeddings<span class="token punctuation">)</span>

        encoder_layer <span class="token operator">=</span> nn<span class="token punctuation">.</span>TransformerEncoderLayer<span class="token punctuation">(</span>
            d_model<span class="token operator">=</span>config<span class="token punctuation">.</span>d_model<span class="token punctuation">,</span>
            nhead<span class="token operator">=</span>config<span class="token punctuation">.</span>num_heads<span class="token punctuation">,</span>
            dim_feedforward<span class="token operator">=</span>config<span class="token punctuation">.</span>dim_feedforward<span class="token punctuation">,</span>
            dropout<span class="token operator">=</span>config<span class="token punctuation">.</span>dropout<span class="token punctuation">,</span>
            batch_first<span class="token operator">=</span><span class="token boolean">True</span>
        <span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>encoder <span class="token operator">=</span> nn<span class="token punctuation">.</span>TransformerEncoder<span class="token punctuation">(</span>encoder_layer<span class="token punctuation">,</span> num_layers<span class="token operator">=</span>config<span class="token punctuation">.</span>num_encoder_layers<span class="token punctuation">)</span>

        decoder_layer <span class="token operator">=</span> nn<span class="token punctuation">.</span>TransformerDecoderLayer<span class="token punctuation">(</span>
            d_model<span class="token operator">=</span>config<span class="token punctuation">.</span>d_model<span class="token punctuation">,</span>
            nhead<span class="token operator">=</span>config<span class="token punctuation">.</span>num_heads<span class="token punctuation">,</span>
            dim_feedforward<span class="token operator">=</span>config<span class="token punctuation">.</span>dim_feedforward<span class="token punctuation">,</span>
            dropout<span class="token operator">=</span>config<span class="token punctuation">.</span>dropout<span class="token punctuation">,</span>
            batch_first<span class="token operator">=</span><span class="token boolean">True</span>
        <span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>decoder <span class="token operator">=</span> nn<span class="token punctuation">.</span>TransformerDecoder<span class="token punctuation">(</span>decoder_layer<span class="token punctuation">,</span> num_layers<span class="token operator">=</span>config<span class="token punctuation">.</span>num_decoder_layers<span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>output_layer <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>config<span class="token punctuation">.</span>d_model<span class="token punctuation">,</span> config<span class="token punctuation">.</span>vocab_size<span class="token punctuation">)</span>

        self<span class="token punctuation">.</span><span class="token builtin">apply</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>_init_weights<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">_init_weights</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> module<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>module<span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">)</span><span class="token punctuation">:</span>
            module<span class="token punctuation">.</span>weight<span class="token punctuation">.</span>data<span class="token punctuation">.</span>normal_<span class="token punctuation">(</span>mean<span class="token operator">=</span><span class="token number">0.0</span><span class="token punctuation">,</span> std<span class="token operator">=</span>self<span class="token punctuation">.</span>cfg<span class="token punctuation">.</span>initializer_range<span class="token punctuation">)</span>
            <span class="token keyword">if</span> module<span class="token punctuation">.</span>bias <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
                module<span class="token punctuation">.</span>bias<span class="token punctuation">.</span>data<span class="token punctuation">.</span>zero_<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">elif</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>module<span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Embedding<span class="token punctuation">)</span><span class="token punctuation">:</span>
            module<span class="token punctuation">.</span>weight<span class="token punctuation">.</span>data<span class="token punctuation">.</span>normal_<span class="token punctuation">(</span>mean<span class="token operator">=</span><span class="token number">0.0</span><span class="token punctuation">,</span> std<span class="token operator">=</span>self<span class="token punctuation">.</span>cfg<span class="token punctuation">.</span>initializer_range<span class="token punctuation">)</span>
            <span class="token keyword">if</span> module<span class="token punctuation">.</span>padding_idx <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
                module<span class="token punctuation">.</span>weight<span class="token punctuation">.</span>data<span class="token punctuation">[</span>module<span class="token punctuation">.</span>padding_idx<span class="token punctuation">]</span><span class="token punctuation">.</span>zero_<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">elif</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>module<span class="token punctuation">,</span> nn<span class="token punctuation">.</span>LayerNorm<span class="token punctuation">)</span><span class="token punctuation">:</span>
            module<span class="token punctuation">.</span>bias<span class="token punctuation">.</span>data<span class="token punctuation">.</span>zero_<span class="token punctuation">(</span><span class="token punctuation">)</span>
            module<span class="token punctuation">.</span>weight<span class="token punctuation">.</span>data<span class="token punctuation">.</span>fill_<span class="token punctuation">(</span><span class="token number">1.0</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> src<span class="token punctuation">,</span> tgt<span class="token punctuation">,</span> src_mask<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> tgt_mask<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        max_len <span class="token operator">=</span> self<span class="token punctuation">.</span>cfg<span class="token punctuation">.</span>max_position_embeddings
        <span class="token keyword">if</span> src<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">&gt;</span> max_len<span class="token punctuation">:</span>
            src <span class="token operator">=</span> src<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span>max_len<span class="token punctuation">]</span>
            <span class="token keyword">if</span> src_mask <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
                src_mask <span class="token operator">=</span> src_mask<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span>max_len<span class="token punctuation">]</span>
        <span class="token keyword">if</span> tgt<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">&gt;</span> max_len<span class="token punctuation">:</span>
            tgt <span class="token operator">=</span> tgt<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span>max_len<span class="token punctuation">]</span>
            <span class="token keyword">if</span> tgt_mask <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span> <span class="token keyword">and</span> tgt_mask<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token operator">&gt;</span> max_len<span class="token punctuation">:</span>
                tgt_mask <span class="token operator">=</span> tgt_mask<span class="token punctuation">[</span><span class="token punctuation">:</span>max_len<span class="token punctuation">,</span> <span class="token punctuation">:</span>max_len<span class="token punctuation">]</span>

        src_emb <span class="token operator">=</span> self<span class="token punctuation">.</span>positional_encoding<span class="token punctuation">(</span>self<span class="token punctuation">.</span>src_embedding<span class="token punctuation">(</span>src<span class="token punctuation">)</span> <span class="token operator">*</span> math<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>self<span class="token punctuation">.</span>cfg<span class="token punctuation">.</span>d_model<span class="token punctuation">)</span><span class="token punctuation">)</span>
        tgt_emb <span class="token operator">=</span> self<span class="token punctuation">.</span>positional_encoding<span class="token punctuation">(</span>self<span class="token punctuation">.</span>tgt_embedding<span class="token punctuation">(</span>tgt<span class="token punctuation">)</span> <span class="token operator">*</span> math<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>self<span class="token punctuation">.</span>cfg<span class="token punctuation">.</span>d_model<span class="token punctuation">)</span><span class="token punctuation">)</span>

        memory <span class="token operator">=</span> self<span class="token punctuation">.</span>encoder<span class="token punctuation">(</span>src_emb<span class="token punctuation">,</span> src_key_padding_mask<span class="token operator">=</span>src_mask<span class="token punctuation">)</span>

        output <span class="token operator">=</span> self<span class="token punctuation">.</span>decoder<span class="token punctuation">(</span>tgt_emb<span class="token punctuation">,</span> memory<span class="token punctuation">,</span> tgt_mask<span class="token operator">=</span>tgt_mask<span class="token punctuation">,</span> memory_key_padding_mask<span class="token operator">=</span>src_mask<span class="token punctuation">)</span>

        logits <span class="token operator">=</span> self<span class="token punctuation">.</span>output_layer<span class="token punctuation">(</span>output<span class="token punctuation">)</span>

        <span class="token keyword">return</span> logits

model <span class="token operator">=</span> TranslationModel<span class="token punctuation">(</span>TranslationModelConfig<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">"cuda"</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">"cpu"</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Using device: </span><span class="token interpolation"><span class="token punctuation">{</span>device<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>

optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">1e-4</span><span class="token punctuation">)</span>

criterion <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span>ignore_index<span class="token operator">=</span>pad_token_id<span class="token punctuation">)</span>

batch_size <span class="token operator">=</span> <span class="token number">32</span>
seq_len <span class="token operator">=</span> <span class="token number">256</span>

<span class="token keyword">class</span> <span class="token class-name">PairedDataset</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>Dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> src_data<span class="token punctuation">,</span> tgt_data<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>tokenizer <span class="token operator">=</span> tokenizer
        <span class="token keyword">assert</span> <span class="token builtin">len</span><span class="token punctuation">(</span>src_data<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token builtin">len</span><span class="token punctuation">(</span>tgt_data<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">"Source and target data must have the same length."</span>
        self<span class="token punctuation">.</span>src_data <span class="token operator">=</span> src_data
        self<span class="token punctuation">.</span>tgt_data <span class="token operator">=</span> tgt_data
        self<span class="token punctuation">.</span>max_len <span class="token operator">=</span> <span class="token number">512</span>

    <span class="token keyword">def</span> <span class="token function">__len__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>src_data<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">__getitem__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> idx<span class="token punctuation">)</span><span class="token punctuation">:</span>
        src_ids <span class="token operator">=</span> tokenizer<span class="token punctuation">.</span>encode<span class="token punctuation">(</span>self<span class="token punctuation">.</span>src_data<span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>ids
        tgt_ids <span class="token operator">=</span> tokenizer<span class="token punctuation">.</span>encode<span class="token punctuation">(</span>self<span class="token punctuation">.</span>tgt_data<span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>ids
        <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>src_ids<span class="token punctuation">)</span> <span class="token operator">&gt;</span> self<span class="token punctuation">.</span>max_len<span class="token punctuation">:</span>
            src_ids <span class="token operator">=</span> src_ids<span class="token punctuation">[</span><span class="token punctuation">:</span>self<span class="token punctuation">.</span>max_len<span class="token punctuation">]</span>
        <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>tgt_ids<span class="token punctuation">)</span> <span class="token operator">&gt;</span> self<span class="token punctuation">.</span>max_len<span class="token punctuation">:</span>
            tgt_ids <span class="token operator">=</span> tgt_ids<span class="token punctuation">[</span><span class="token punctuation">:</span>self<span class="token punctuation">.</span>max_len<span class="token punctuation">]</span>
        <span class="token keyword">return</span> src_ids<span class="token punctuation">,</span> tgt_ids

dataset <span class="token operator">=</span> PairedDataset<span class="token punctuation">(</span>
    <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">'./notebooks/processed.hi'</span><span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>readlines<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">'./notebooks/processed.en'</span><span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>readlines<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token punctuation">)</span>

train_size <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span><span class="token number">0.8</span> <span class="token operator">*</span> <span class="token builtin">len</span><span class="token punctuation">(</span>dataset<span class="token punctuation">)</span><span class="token punctuation">)</span>
val_size <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span><span class="token number">0.1</span> <span class="token operator">*</span> <span class="token builtin">len</span><span class="token punctuation">(</span>dataset<span class="token punctuation">)</span><span class="token punctuation">)</span>
test_size <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>dataset<span class="token punctuation">)</span> <span class="token operator">-</span> train_size <span class="token operator">-</span> val_size
train_dataset<span class="token punctuation">,</span> val_dataset<span class="token punctuation">,</span> test_dataset <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>random_split<span class="token punctuation">(</span>dataset<span class="token punctuation">,</span> <span class="token punctuation">[</span>train_size<span class="token punctuation">,</span> val_size<span class="token punctuation">,</span> test_size<span class="token punctuation">]</span><span class="token punctuation">)</span>

train_dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>train_dataset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> collate_fn<span class="token operator">=</span><span class="token keyword">lambda</span> batch<span class="token punctuation">:</span> <span class="token punctuation">(</span>
    torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>rnn<span class="token punctuation">.</span>pad_sequence<span class="token punctuation">(</span><span class="token punctuation">[</span>torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>item<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">512</span><span class="token punctuation">]</span> <span class="token keyword">for</span> item <span class="token keyword">in</span> batch<span class="token punctuation">]</span><span class="token punctuation">,</span> batch_first<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> padding_value<span class="token operator">=</span>pad_token_id<span class="token punctuation">)</span><span class="token punctuation">,</span>
    torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>rnn<span class="token punctuation">.</span>pad_sequence<span class="token punctuation">(</span><span class="token punctuation">[</span>torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>item<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">512</span><span class="token punctuation">]</span> <span class="token keyword">for</span> item <span class="token keyword">in</span> batch<span class="token punctuation">]</span><span class="token punctuation">,</span> batch_first<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> padding_value<span class="token operator">=</span>pad_token_id<span class="token punctuation">)</span>
<span class="token punctuation">)</span><span class="token punctuation">)</span>

num_epochs <span class="token operator">=</span> <span class="token number">500</span>

checkpoint_dir <span class="token operator">=</span> <span class="token string">"checkpoints"</span>
os<span class="token punctuation">.</span>makedirs<span class="token punctuation">(</span>checkpoint_dir<span class="token punctuation">,</span> exist_ok<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

latest_checkpoint <span class="token operator">=</span> <span class="token boolean">None</span>
checkpoints <span class="token operator">=</span> <span class="token builtin">sorted</span><span class="token punctuation">(</span>glob<span class="token punctuation">.</span>glob<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>checkpoint_dir<span class="token punctuation">,</span> <span class="token string">"checkpoint_epoch_*.pt"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">if</span> checkpoints<span class="token punctuation">:</span>
    latest_checkpoint <span class="token operator">=</span> checkpoints<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>

start_epoch <span class="token operator">=</span> <span class="token number">0</span>
<span class="token keyword">if</span> latest_checkpoint <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Loading checkpoint from </span><span class="token interpolation"><span class="token punctuation">{</span>latest_checkpoint<span class="token punctuation">}</span></span><span class="token string"> to resume training..."</span></span><span class="token punctuation">)</span>
    checkpoint <span class="token operator">=</span> torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>latest_checkpoint<span class="token punctuation">,</span> map_location<span class="token operator">=</span>device<span class="token punctuation">)</span>
    model<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>checkpoint<span class="token punctuation">[</span><span class="token string">'model_state_dict'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    optimizer<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>checkpoint<span class="token punctuation">[</span><span class="token string">'optimizer_state_dict'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    start_epoch <span class="token operator">=</span> checkpoint<span class="token punctuation">[</span><span class="token string">'epoch'</span><span class="token punctuation">]</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Resuming from epoch </span><span class="token interpolation"><span class="token punctuation">{</span>start_epoch<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"\nStarting training loop on actual data..."</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>start_epoch<span class="token punctuation">,</span> num_epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>
    model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
    total_loss <span class="token operator">=</span> <span class="token number">0</span>

    <span class="token keyword">for</span> batch_idx<span class="token punctuation">,</span> <span class="token punctuation">(</span>src_batch<span class="token punctuation">,</span> tgt_batch<span class="token punctuation">)</span> <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>tqdm<span class="token punctuation">(</span>train_dataloader<span class="token punctuation">,</span> ncols<span class="token operator">=</span><span class="token number">80</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        src_batch<span class="token punctuation">,</span> tgt_batch <span class="token operator">=</span> src_batch<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">,</span> tgt_batch<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>

        src_mask <span class="token operator">=</span> <span class="token punctuation">(</span>src_batch <span class="token operator">==</span> pad_token_id<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>

        decoder_input <span class="token operator">=</span> tgt_batch<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>
        target_labels <span class="token operator">=</span> tgt_batch<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span>

        decoder_input_seq_len <span class="token operator">=</span> decoder_input<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
        causal_tgt_mask <span class="token operator">=</span> torch<span class="token punctuation">.</span>triu<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span>decoder_input_seq_len<span class="token punctuation">,</span> decoder_input_seq_len<span class="token punctuation">)</span><span class="token punctuation">,</span> diagonal<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">bool</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>

        output_logits <span class="token operator">=</span> model<span class="token punctuation">(</span>src_batch<span class="token punctuation">,</span> decoder_input<span class="token punctuation">,</span> src_mask<span class="token operator">=</span>src_mask<span class="token punctuation">,</span> tgt_mask<span class="token operator">=</span>causal_tgt_mask<span class="token punctuation">)</span>

        loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>output_logits<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> model<span class="token punctuation">.</span>cfg<span class="token punctuation">.</span>vocab_size<span class="token punctuation">)</span><span class="token punctuation">,</span> target_labels<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>

        total_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>

    avg_loss <span class="token operator">=</span> total_loss <span class="token operator">/</span> <span class="token builtin">len</span><span class="token punctuation">(</span>train_dataloader<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Epoch </span><span class="token interpolation"><span class="token punctuation">{</span>epoch<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">}</span></span><span class="token string">/</span><span class="token interpolation"><span class="token punctuation">{</span>num_epochs<span class="token punctuation">}</span></span><span class="token string">, Average Loss: </span><span class="token interpolation"><span class="token punctuation">{</span>avg_loss<span class="token punctuation">:</span><span class="token format-spec">.4f</span><span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>

    checkpoint_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>checkpoint_dir<span class="token punctuation">,</span> <span class="token string-interpolation"><span class="token string">f"checkpoint_epoch_</span><span class="token interpolation"><span class="token punctuation">{</span>epoch<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">}</span></span><span class="token string">.pt"</span></span><span class="token punctuation">)</span>
    torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span><span class="token punctuation">{</span>
        <span class="token string">'epoch'</span><span class="token punctuation">:</span> epoch <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span>
        <span class="token string">'model_state_dict'</span><span class="token punctuation">:</span> model<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        <span class="token string">'optimizer_state_dict'</span><span class="token punctuation">:</span> optimizer<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        <span class="token string">'loss'</span><span class="token punctuation">:</span> avg_loss
    <span class="token punctuation">}</span><span class="token punctuation">,</span> checkpoint_path<span class="token punctuation">)</span>

    checkpoints <span class="token operator">=</span> <span class="token builtin">sorted</span><span class="token punctuation">(</span>glob<span class="token punctuation">.</span>glob<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>checkpoint_dir<span class="token punctuation">,</span> <span class="token string">"checkpoint_epoch_*.pt"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>checkpoints<span class="token punctuation">)</span> <span class="token operator">&gt;</span> <span class="token number">2</span><span class="token punctuation">:</span>
        os<span class="token punctuation">.</span>remove<span class="token punctuation">(</span>checkpoints<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"\nTraining loop on actual data finished."</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"If the 'Average Loss' is decreasing over epochs, your model is training!"</span><span class="token punctuation">)</span>
</code><button class="copy-code-button"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon lucide-copy"><rect x="8" y="8" width="14" height="14" rx="2" ry="2"></rect><path d="M4 16c-1.1 0-2-.9-2-2V4c0-1.1.9-2 2-2h10c1.1 0 2 .9 2 2"></path></svg></button></pre></div><div class="footer"><div class="data-bar"></div></div></div></div></div><div id="right-content" class="leaf" style="--sidebar-width: var(--sidebar-width-right);"><div id="right-sidebar" class="sidebar"><div class="sidebar-handle"></div><div class="sidebar-topbar"><div class="topbar-content"></div><div class="clickable-icon sidebar-collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="100%" height="100%" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="3" stroke-linecap="round" stroke-linejoin="round" class="svg-icon"><path d="M21 3H3C1.89543 3 1 3.89543 1 5V19C1 20.1046 1.89543 21 3 21H21C22.1046 21 23 20.1046 23 19V5C23 3.89543 22.1046 3 21 3Z"></path><path d="M10 4V20"></path><path d="M4 7H7"></path><path d="M4 10H7"></path><path d="M4 13H7"></path></svg></div></div><div class="sidebar-content-wrapper"><div id="right-sidebar-content" class="leaf-content"><div id="outline" class=" tree-container"><div class="feature-header"><div class="feature-title">Table Of Contents</div><button class="clickable-icon nav-action-button tree-collapse-all" aria-label="Collapse All"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"></svg></button></div><div class="tree-item mod-collapsible" data-depth="1"><a class="tree-item-self is-clickable mod-collapsible" href="machine-learning/huggingface-llm-course.html#HuggingFace_LLM_Course_0" data-path="#HuggingFace_LLM_Course_0"><div class="tree-item-icon collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div><div class="tree-item-inner heading-link" heading-name="HuggingFace: LLM Course">HuggingFace: LLM Course</div></a><div class="tree-item-children"><div class="tree-item mod-collapsible" data-depth="2"><a class="tree-item-self is-clickable mod-collapsible" href="machine-learning/huggingface-llm-course.html#0._SETUP_0" data-path="#0._SETUP_0"><div class="tree-item-icon collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div><div class="tree-item-inner heading-link" heading-name="0. SETUP">0. SETUP</div></a><div class="tree-item-children"><div class="tree-item" data-depth="3"><a class="tree-item-self is-clickable" href="machine-learning/huggingface-llm-course.html#Commonly_used_libraries_0" data-path="#Commonly_used_libraries_0"><div class="tree-item-inner heading-link" heading-name="Commonly used libraries">Commonly used libraries</div></a><div class="tree-item-children"></div></div></div></div><div class="tree-item mod-collapsible" data-depth="2"><a class="tree-item-self is-clickable mod-collapsible" href="machine-learning/huggingface-llm-course.html#1._TRANSFORMER_MODELS_0" data-path="#1._TRANSFORMER_MODELS_0"><div class="tree-item-icon collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div><div class="tree-item-inner heading-link" heading-name="1. TRANSFORMER MODELS">1. TRANSFORMER MODELS</div></a><div class="tree-item-children"><div class="tree-item" data-depth="3"><a class="tree-item-self is-clickable" href="machine-learning/huggingface-llm-course.html#Pipeline()_Function_0" data-path="#Pipeline()_Function_0"><div class="tree-item-inner heading-link" heading-name="Pipeline() Function">Pipeline() Function</div></a><div class="tree-item-children"></div></div><div class="tree-item" data-depth="3"><a class="tree-item-self is-clickable" href="machine-learning/huggingface-llm-course.html#Tasks_and_Pipeline()_Compatibility_0" data-path="#Tasks_and_Pipeline()_Compatibility_0"><div class="tree-item-inner heading-link" heading-name="Tasks and Pipeline() Compatibility">Tasks and Pipeline() Compatibility</div></a><div class="tree-item-children"></div></div><div class="tree-item mod-collapsible" data-depth="3"><a class="tree-item-self is-clickable mod-collapsible" href="machine-learning/huggingface-llm-course.html#Classification_of_LLM_Models_0" data-path="#Classification_of_LLM_Models_0"><div class="tree-item-icon collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div><div class="tree-item-inner heading-link" heading-name="Classification of LLM Models">Classification of LLM Models</div></a><div class="tree-item-children"><div class="tree-item" data-depth="4"><a class="tree-item-self is-clickable" href="machine-learning/huggingface-llm-course.html#1_Encoder_Based_(Auto-Encoding_Transformers)_0" data-path="#1_Encoder_Based_(Auto-Encoding_Transformers)_0"><div class="tree-item-inner heading-link" heading-name="1: Encoder Based (Auto-Encoding Transformers)">1: Encoder Based (Auto-Encoding Transformers)</div></a><div class="tree-item-children"></div></div><div class="tree-item" data-depth="4"><a class="tree-item-self is-clickable" href="machine-learning/huggingface-llm-course.html#2_Decoder_Based_(Auto-Regressive_Transformers)_0" data-path="#2_Decoder_Based_(Auto-Regressive_Transformers)_0"><div class="tree-item-inner heading-link" heading-name="2: Decoder Based (Auto-Regressive Transformers)">2: Decoder Based (Auto-Regressive Transformers)</div></a><div class="tree-item-children"></div></div><div class="tree-item" data-depth="4"><a class="tree-item-self is-clickable" href="machine-learning/huggingface-llm-course.html#3_Encoder_+_Decoder_Based_Transformers_0" data-path="#3_Encoder_+_Decoder_Based_Transformers_0"><div class="tree-item-inner heading-link" heading-name="3: Encoder + Decoder Based Transformers">3: Encoder + Decoder Based Transformers</div></a><div class="tree-item-children"></div></div></div></div><div class="tree-item mod-collapsible" data-depth="3"><a class="tree-item-self is-clickable mod-collapsible" href="machine-learning/huggingface-llm-course.html#Auto-Encoding_Models_0" data-path="#Auto-Encoding_Models_0"><div class="tree-item-icon collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div><div class="tree-item-inner heading-link" heading-name="Auto-Encoding Models">Auto-Encoding Models</div></a><div class="tree-item-children"><div class="tree-item" data-depth="4"><a class="tree-item-self is-clickable" href="machine-learning/huggingface-llm-course.html#Model_BaseAutoEncodingModel_0" data-path="#Model_BaseAutoEncodingModel_0"><div class="tree-item-inner heading-link" heading-name="Model: BaseAutoEncodingModel">Model: BaseAutoEncodingModel</div></a><div class="tree-item-children"></div></div><div class="tree-item" data-depth="4"><a class="tree-item-self is-clickable" href="machine-learning/huggingface-llm-course.html#Module_BaseAutoEncodingModelEmbedder_0" data-path="#Module_BaseAutoEncodingModelEmbedder_0"><div class="tree-item-inner heading-link" heading-name="Module: BaseAutoEncodingModelEmbedder">Module: BaseAutoEncodingModelEmbedder</div></a><div class="tree-item-children"></div></div><div class="tree-item" data-depth="4"><a class="tree-item-self is-clickable" href="machine-learning/huggingface-llm-course.html#Module_BaseAutoEncodingModelEncoder_0" data-path="#Module_BaseAutoEncodingModelEncoder_0"><div class="tree-item-inner heading-link" heading-name="Module: BaseAutoEncodingModelEncoder">Module: BaseAutoEncodingModelEncoder</div></a><div class="tree-item-children"></div></div><div class="tree-item" data-depth="4"><a class="tree-item-self is-clickable" href="machine-learning/huggingface-llm-course.html#Module_BaseAutoEncodingModelPooler_0" data-path="#Module_BaseAutoEncodingModelPooler_0"><div class="tree-item-inner heading-link" heading-name="Module: BaseAutoEncodingModelPooler">Module: BaseAutoEncodingModelPooler</div></a><div class="tree-item-children"></div></div></div></div></div></div><div class="tree-item" data-depth="2"><a class="tree-item-self is-clickable" href="machine-learning/huggingface-llm-course.html#Train_Sequence_to_Sequence_Model_0" data-path="#Train_Sequence_to_Sequence_Model_0"><div class="tree-item-inner heading-link" heading-name="Train Sequence to Sequence Model">Train Sequence to Sequence Model</div></a><div class="tree-item-children"></div></div></div></div></div></div></div><script defer="">let rs = document.querySelector("#right-sidebar"); rs.classList.toggle("is-collapsed", window.innerWidth < 768); rs.style.setProperty("--sidebar-width", localStorage.getItem("sidebar-right-width"));</script></div></div></div></div></body></html>